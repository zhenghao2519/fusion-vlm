{"env_info": "sys.platform: linux\nPython: 3.9.21 (main, Dec 11 2024, 16:24:11) [GCC 11.2.0]\nCUDA available: True\nGPU 0: NVIDIA GeForce RTX 3090 Ti\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 11.8, V11.8.89\nGCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\nPyTorch: 1.13.1\nPyTorch compiling details: PyTorch built with:\n  - GCC 9.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.7\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 8.5\n  - Magma 2.6.1\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.14.1\nOpenCV: 4.11.0\nMMCV: 1.6.2\nMMCV Compiler: GCC 11.4\nMMCV CUDA Compiler: 11.8\nMMDetection: 2.28.2\nMMSegmentation: 0.30.0\nMMDetection3D: 1.0.0rc6+7175f0d\nspconv2.0: True", "config": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ndataset_type = 'CustomNuScenesDataset'\ndata_root = './data/nuscenes/'\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=True)\nfile_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(\n        type='LoadAnnotations3D',\n        with_bbox_3d=True,\n        with_label_3d=True,\n        with_bbox=True,\n        with_label=True,\n        with_bbox_depth=True),\n    dict(\n        type='ObjectRangeFilter',\n        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),\n    dict(\n        type='ObjectNameFilter',\n        classes=[\n            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n        ]),\n    dict(\n        type='ResizeCropFlipRotImage',\n        data_aug_conf=dict(\n            resize_lim=(0.37, 0.45),\n            final_dim=(320, 640),\n            bot_pct_lim=(0.0, 0.0),\n            rot_lim=(0.0, 0.0),\n            H=900,\n            W=1600,\n            rand_flip=False),\n        training=True),\n    dict(\n        type='ResizeMultiview3D',\n        img_scale=(640, 640),\n        keep_ratio=False,\n        multiscale_mode='value'),\n    dict(\n        type='LoadAnnoatationVQA',\n        base_vqa_path='./data/nuscenes/vqa/train/',\n        base_desc_path='./data/nuscenes/desc/train/',\n        base_conv_path='./data/nuscenes/conv/train/',\n        base_key_path='./data/nuscenes/keywords/train/',\n        tokenizer='ckpts/pretrain_qformer/',\n        max_length=2048,\n        ignore_type=[],\n        lane_objs_info='./data/nuscenes/lane_obj_train.pkl'),\n    dict(\n        type='NormalizeMultiviewImage',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='PETRFormatBundle3D',\n        class_names=[\n            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n        ],\n        collect_keys=[\n            'lidar2img', 'intrinsics', 'extrinsics', 'timestamp',\n            'img_timestamp', 'ego_pose', 'ego_pose_inv', 'command', 'can_bus',\n            'prev_exists'\n        ]),\n    dict(\n        type='Collect3D',\n        keys=[\n            'lane_pts', 'input_ids', 'vlm_labels', 'gt_bboxes_3d',\n            'gt_labels_3d', 'img', 'gt_bboxes', 'gt_labels', 'centers2d',\n            'depths', 'prev_exists', 'lidar2img', 'intrinsics', 'extrinsics',\n            'timestamp', 'img_timestamp', 'ego_pose', 'ego_pose_inv',\n            'command', 'can_bus'\n        ],\n        meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',\n                   'scale_factor', 'flip', 'box_mode_3d', 'box_type_3d',\n                   'img_norm_cfg', 'scene_token', 'gt_bboxes_3d',\n                   'gt_labels_3d'))\n]\ntest_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(\n        type='ResizeCropFlipRotImage',\n        data_aug_conf=dict(\n            resize_lim=(0.37, 0.45),\n            final_dim=(320, 640),\n            bot_pct_lim=(0.0, 0.0),\n            rot_lim=(0.0, 0.0),\n            H=900,\n            W=1600,\n            rand_flip=False),\n        training=False),\n    dict(\n        type='ResizeMultiview3D',\n        img_scale=(640, 640),\n        keep_ratio=False,\n        multiscale_mode='value'),\n    dict(\n        type='NormalizeMultiviewImage',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='LoadAnnoatationVQATest',\n        base_vqa_path='./data/nuscenes/vqa/val/',\n        base_conv_path='./data/nuscenes/conv/val/',\n        base_counter_path='./data/nuscenes/eval_cf/',\n        load_type=['planning'],\n        tokenizer='ckpts/pretrain_qformer/',\n        max_length=2048),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1333, 800),\n        pts_scale_ratio=1,\n        flip=False,\n        transforms=[\n            dict(\n                type='PETRFormatBundle3D',\n                collect_keys=[\n                    'lidar2img', 'intrinsics', 'extrinsics', 'timestamp',\n                    'img_timestamp', 'ego_pose', 'ego_pose_inv', 'command',\n                    'can_bus'\n                ],\n                class_names=[\n                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',\n                    'traffic_cone'\n                ],\n                with_label=False),\n            dict(\n                type='Collect3D',\n                keys=[\n                    'input_ids', 'img', 'lidar2img', 'intrinsics',\n                    'extrinsics', 'timestamp', 'img_timestamp', 'ego_pose',\n                    'ego_pose_inv', 'command', 'can_bus'\n                ],\n                meta_keys=('sample_idx', 'vlm_labels', 'filename', 'ori_shape',\n                           'img_shape', 'pad_shape', 'scale_factor', 'flip',\n                           'box_mode_3d', 'box_type_3d', 'img_norm_cfg',\n                           'scene_token'))\n        ])\n]\neval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=dict(backend='disk')),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,\n        file_client_args=dict(backend='disk')),\n    dict(\n        type='DefaultFormatBundle3D',\n        class_names=[\n            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',\n            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n        ],\n        with_label=False),\n    dict(type='Collect3D', keys=['points'])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type='CustomNuScenesDataset',\n        data_root='./data/nuscenes/',\n        ann_file='./data/nuscenes/nuscenes2d_ego_temporal_infos_train.pkl',\n        pipeline=[\n            dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n            dict(\n                type='LoadAnnotations3D',\n                with_bbox_3d=True,\n                with_label_3d=True,\n                with_bbox=True,\n                with_label=True,\n                with_bbox_depth=True),\n            dict(\n                type='ObjectRangeFilter',\n                point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),\n            dict(\n                type='ObjectNameFilter',\n                classes=[\n                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',\n                    'traffic_cone'\n                ]),\n            dict(\n                type='ResizeCropFlipRotImage',\n                data_aug_conf=dict(\n                    resize_lim=(0.37, 0.45),\n                    final_dim=(320, 640),\n                    bot_pct_lim=(0.0, 0.0),\n                    rot_lim=(0.0, 0.0),\n                    H=900,\n                    W=1600,\n                    rand_flip=False),\n                training=True),\n            dict(\n                type='ResizeMultiview3D',\n                img_scale=(640, 640),\n                keep_ratio=False,\n                multiscale_mode='value'),\n            dict(\n                type='LoadAnnoatationVQA',\n                base_vqa_path='./data/nuscenes/vqa/train/',\n                base_desc_path='./data/nuscenes/desc/train/',\n                base_conv_path='./data/nuscenes/conv/train/',\n                base_key_path='./data/nuscenes/keywords/train/',\n                tokenizer='ckpts/pretrain_qformer/',\n                max_length=2048,\n                ignore_type=[],\n                lane_objs_info='./data/nuscenes/lane_obj_train.pkl'),\n            dict(\n                type='NormalizeMultiviewImage',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='PadMultiViewImage', size_divisor=32),\n            dict(\n                type='PETRFormatBundle3D',\n                class_names=[\n                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',\n                    'traffic_cone'\n                ],\n                collect_keys=[\n                    'lidar2img', 'intrinsics', 'extrinsics', 'timestamp',\n                    'img_timestamp', 'ego_pose', 'ego_pose_inv', 'command',\n                    'can_bus', 'prev_exists'\n                ]),\n            dict(\n                type='Collect3D',\n                keys=[\n                    'lane_pts', 'input_ids', 'vlm_labels', 'gt_bboxes_3d',\n                    'gt_labels_3d', 'img', 'gt_bboxes', 'gt_labels',\n                    'centers2d', 'depths', 'prev_exists', 'lidar2img',\n                    'intrinsics', 'extrinsics', 'timestamp', 'img_timestamp',\n                    'ego_pose', 'ego_pose_inv', 'command', 'can_bus'\n                ],\n                meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',\n                           'scale_factor', 'flip', 'box_mode_3d',\n                           'box_type_3d', 'img_norm_cfg', 'scene_token',\n                           'gt_bboxes_3d', 'gt_labels_3d'))\n        ],\n        classes=[\n            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n        ],\n        modality=dict(\n            use_lidar=False,\n            use_camera=True,\n            use_radar=False,\n            use_map=False,\n            use_external=True),\n        test_mode=False,\n        box_type_3d='LiDAR',\n        seq_split_num=1,\n        seq_mode=True,\n        use_valid_flag=True,\n        filter_empty_gt=False),\n    val=dict(\n        type='CustomNuScenesDataset',\n        data_root='data/nuscenes/',\n        ann_file='./data/nuscenes/nuscenes2d_ego_temporal_infos_val.pkl',\n        pipeline=[\n            dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n            dict(\n                type='ResizeCropFlipRotImage',\n                data_aug_conf=dict(\n                    resize_lim=(0.37, 0.45),\n                    final_dim=(320, 640),\n                    bot_pct_lim=(0.0, 0.0),\n                    rot_lim=(0.0, 0.0),\n                    H=900,\n                    W=1600,\n                    rand_flip=False),\n                training=False),\n            dict(\n                type='ResizeMultiview3D',\n                img_scale=(640, 640),\n                keep_ratio=False,\n                multiscale_mode='value'),\n            dict(\n                type='NormalizeMultiviewImage',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='PadMultiViewImage', size_divisor=32),\n            dict(\n                type='LoadAnnoatationVQATest',\n                base_vqa_path='./data/nuscenes/vqa/val/',\n                base_conv_path='./data/nuscenes/conv/val/',\n                base_counter_path='./data/nuscenes/eval_cf/',\n                load_type=['planning'],\n                tokenizer='ckpts/pretrain_qformer/',\n                max_length=2048),\n            dict(\n                type='MultiScaleFlipAug3D',\n                img_scale=(1333, 800),\n                pts_scale_ratio=1,\n                flip=False,\n                transforms=[\n                    dict(\n                        type='PETRFormatBundle3D',\n                        collect_keys=[\n                            'lidar2img', 'intrinsics', 'extrinsics',\n                            'timestamp', 'img_timestamp', 'ego_pose',\n                            'ego_pose_inv', 'command', 'can_bus'\n                        ],\n                        class_names=[\n                            'car', 'truck', 'construction_vehicle', 'bus',\n                            'trailer', 'barrier', 'motorcycle', 'bicycle',\n                            'pedestrian', 'traffic_cone'\n                        ],\n                        with_label=False),\n                    dict(\n                        type='Collect3D',\n                        keys=[\n                            'input_ids', 'img', 'lidar2img', 'intrinsics',\n                            'extrinsics', 'timestamp', 'img_timestamp',\n                            'ego_pose', 'ego_pose_inv', 'command', 'can_bus'\n                        ],\n                        meta_keys=('sample_idx', 'vlm_labels', 'filename',\n                                   'ori_shape', 'img_shape', 'pad_shape',\n                                   'scale_factor', 'flip', 'box_mode_3d',\n                                   'box_type_3d', 'img_norm_cfg',\n                                   'scene_token'))\n                ])\n        ],\n        classes=[\n            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n        ],\n        modality=dict(\n            use_lidar=False,\n            use_camera=True,\n            use_radar=False,\n            use_map=False,\n            use_external=True),\n        test_mode=True,\n        box_type_3d='LiDAR',\n        eval_mode=['lane', 'det']),\n    test=dict(\n        type='CustomNuScenesDataset',\n        data_root='data/nuscenes/',\n        ann_file='./data/nuscenes/nuscenes2d_ego_temporal_infos_val.pkl',\n        pipeline=[\n            dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n            dict(\n                type='ResizeCropFlipRotImage',\n                data_aug_conf=dict(\n                    resize_lim=(0.37, 0.45),\n                    final_dim=(320, 640),\n                    bot_pct_lim=(0.0, 0.0),\n                    rot_lim=(0.0, 0.0),\n                    H=900,\n                    W=1600,\n                    rand_flip=False),\n                training=False),\n            dict(\n                type='ResizeMultiview3D',\n                img_scale=(640, 640),\n                keep_ratio=False,\n                multiscale_mode='value'),\n            dict(\n                type='NormalizeMultiviewImage',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='PadMultiViewImage', size_divisor=32),\n            dict(\n                type='LoadAnnoatationVQATest',\n                base_vqa_path='./data/nuscenes/vqa/val/',\n                base_conv_path='./data/nuscenes/conv/val/',\n                base_counter_path='./data/nuscenes/eval_cf/',\n                load_type=['planning'],\n                tokenizer='ckpts/pretrain_qformer/',\n                max_length=2048),\n            dict(\n                type='MultiScaleFlipAug3D',\n                img_scale=(1333, 800),\n                pts_scale_ratio=1,\n                flip=False,\n                transforms=[\n                    dict(\n                        type='PETRFormatBundle3D',\n                        collect_keys=[\n                            'lidar2img', 'intrinsics', 'extrinsics',\n                            'timestamp', 'img_timestamp', 'ego_pose',\n                            'ego_pose_inv', 'command', 'can_bus'\n                        ],\n                        class_names=[\n                            'car', 'truck', 'construction_vehicle', 'bus',\n                            'trailer', 'barrier', 'motorcycle', 'bicycle',\n                            'pedestrian', 'traffic_cone'\n                        ],\n                        with_label=False),\n                    dict(\n                        type='Collect3D',\n                        keys=[\n                            'input_ids', 'img', 'lidar2img', 'intrinsics',\n                            'extrinsics', 'timestamp', 'img_timestamp',\n                            'ego_pose', 'ego_pose_inv', 'command', 'can_bus'\n                        ],\n                        meta_keys=('sample_idx', 'vlm_labels', 'filename',\n                                   'ori_shape', 'img_shape', 'pad_shape',\n                                   'scale_factor', 'flip', 'box_mode_3d',\n                                   'box_type_3d', 'img_norm_cfg',\n                                   'scene_token'))\n                ])\n        ],\n        classes=[\n            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n        ],\n        modality=dict(\n            use_lidar=False,\n            use_camera=True,\n            use_radar=False,\n            use_map=False,\n            use_external=True),\n        test_mode=True,\n        box_type_3d='LiDAR',\n        eval_mode=['lane', 'det']),\n    shuffler_sampler=dict(\n        type='InfiniteGroupEachSampleInBatchSampler',\n        seq_split_num=2,\n        warmup_split_num=10,\n        num_iters_to_seq=14065),\n    nonshuffler_sampler=dict(type='DistributedSampler'))\nevaluation = dict(\n    interval=84390,\n    pipeline=[\n        dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n        dict(\n            type='ResizeCropFlipRotImage',\n            data_aug_conf=dict(\n                resize_lim=(0.37, 0.45),\n                final_dim=(320, 640),\n                bot_pct_lim=(0.0, 0.0),\n                rot_lim=(0.0, 0.0),\n                H=900,\n                W=1600,\n                rand_flip=False),\n            training=False),\n        dict(\n            type='ResizeMultiview3D',\n            img_scale=(640, 640),\n            keep_ratio=False,\n            multiscale_mode='value'),\n        dict(\n            type='NormalizeMultiviewImage',\n            mean=[123.675, 116.28, 103.53],\n            std=[58.395, 57.12, 57.375],\n            to_rgb=True),\n        dict(type='PadMultiViewImage', size_divisor=32),\n        dict(\n            type='LoadAnnoatationVQATest',\n            base_vqa_path='./data/nuscenes/vqa/val/',\n            base_conv_path='./data/nuscenes/conv/val/',\n            base_counter_path='./data/nuscenes/eval_cf/',\n            load_type=['planning'],\n            tokenizer='ckpts/pretrain_qformer/',\n            max_length=2048),\n        dict(\n            type='MultiScaleFlipAug3D',\n            img_scale=(1333, 800),\n            pts_scale_ratio=1,\n            flip=False,\n            transforms=[\n                dict(\n                    type='PETRFormatBundle3D',\n                    collect_keys=[\n                        'lidar2img', 'intrinsics', 'extrinsics', 'timestamp',\n                        'img_timestamp', 'ego_pose', 'ego_pose_inv', 'command',\n                        'can_bus'\n                    ],\n                    class_names=[\n                        'car', 'truck', 'construction_vehicle', 'bus',\n                        'trailer', 'barrier', 'motorcycle', 'bicycle',\n                        'pedestrian', 'traffic_cone'\n                    ],\n                    with_label=False),\n                dict(\n                    type='Collect3D',\n                    keys=[\n                        'input_ids', 'img', 'lidar2img', 'intrinsics',\n                        'extrinsics', 'timestamp', 'img_timestamp', 'ego_pose',\n                        'ego_pose_inv', 'command', 'can_bus'\n                    ],\n                    meta_keys=('sample_idx', 'vlm_labels', 'filename',\n                               'ori_shape', 'img_shape', 'pad_shape',\n                               'scale_factor', 'flip', 'box_mode_3d',\n                               'box_type_3d', 'img_norm_cfg', 'scene_token'))\n            ])\n    ])\ncheckpoint_config = dict(interval=7032, max_keep_ckpts=3)\nlog_config = dict(\n    interval=50,\n    hooks=[dict(type='TextLoggerHook'),\n           dict(type='TensorboardLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nwork_dir = 'work_dirs/mask_eva_lane_det_vlm/'\nload_from = 'ckpts/fcos3d_vovnet_imgbackbone-remapped.pth'\nresume_from = None\nworkflow = [('train', 1)]\nopencv_num_threads = 0\nmp_start_method = 'fork'\nbackbone_norm_cfg = dict(type='LN', requires_grad=True)\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\nnum_gpus = 1\nbatch_size = 2\nnum_iters_per_epoch = 14065\nnum_epochs = 6\nllm_path = 'ckpts/pretrain_qformer/'\ncollect_keys = [\n    'lidar2img', 'intrinsics', 'extrinsics', 'timestamp', 'img_timestamp',\n    'ego_pose', 'ego_pose_inv', 'command', 'can_bus'\n]\nmodel = dict(\n    type='Petr3D',\n    save_path='./results_planning_only/',\n    use_grid_mask=True,\n    frozen=False,\n    use_lora=True,\n    tokenizer='ckpts/pretrain_qformer/',\n    lm_head=None,\n    img_backbone=dict(\n        type='VoVNet',\n        spec_name='V-99-eSE',\n        norm_eval=True,\n        frozen_stages=-1,\n        input_ch=3,\n        out_features='stage4'),\n    img_neck=dict(\n        type='CPFPN', in_channels=[768], out_channels=256, num_outs=2),\n    pts_bbox_head=dict(\n        type='StreamPETRHead',\n        num_classes=10,\n        in_channels=256,\n        out_dims=4096,\n        num_query=600,\n        with_mask=True,\n        memory_len=600,\n        topk_proposals=300,\n        num_propagated=300,\n        num_extra=256,\n        n_control=11,\n        match_with_velo=False,\n        scalar=10,\n        noise_scale=1.0,\n        dn_weight=1.0,\n        split=0.75,\n        code_weights=[2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n        transformer=dict(\n            type='PETRTemporalTransformer',\n            input_dimension=256,\n            output_dimension=256,\n            num_layers=6,\n            embed_dims=256,\n            num_heads=8,\n            feedforward_dims=2048,\n            dropout=0.1,\n            with_cp=True,\n            flash_attn=True),\n        bbox_coder=dict(\n            type='NMSFreeCoder',\n            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],\n            pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],\n            max_num=300,\n            voxel_size=[0.2, 0.2, 8],\n            num_classes=10),\n        loss_cls=dict(\n            type='FocalLoss',\n            use_sigmoid=True,\n            gamma=2.0,\n            alpha=0.25,\n            loss_weight=2.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=0.25),\n        loss_iou=dict(type='GIoULoss', loss_weight=0.0)),\n    train_cfg=dict(\n        pts=dict(\n            grid_size=[512, 512, 1],\n            voxel_size=[0.2, 0.2, 8],\n            point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],\n            out_size_factor=4,\n            assigner=dict(\n                type='HungarianAssigner3D',\n                cls_cost=dict(type='FocalLossCost', weight=2.0),\n                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),\n                iou_cost=dict(type='IoUCost', weight=0.0),\n                pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]))))\nida_aug_conf = dict(\n    resize_lim=(0.37, 0.45),\n    final_dim=(320, 640),\n    bot_pct_lim=(0.0, 0.0),\n    rot_lim=(0.0, 0.0),\n    H=900,\n    W=1600,\n    rand_flip=False)\noptimizer = dict(\n    constructor='LearningRateDecayOptimizerConstructor',\n    type='AdamW',\n    lr=0.0001,\n    betas=(0.9, 0.999),\n    weight_decay=0.0001,\n    paramwise_cfg=dict(\n        decay_rate=0.9,\n        head_decay_rate=4.0,\n        lm_head_decay_rate=0.1,\n        decay_type='vit_wise',\n        num_layers=24))\noptimizer_config = dict(\n    type='Fp16OptimizerHook',\n    loss_scale='dynamic',\n    grad_clip=dict(max_norm=35, norm_type=2))\nlr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.3333333333333333,\n    min_lr_ratio=0.001)\nfind_unused_parameters = False\nrunner = dict(type='IterBasedRunner', max_iters=84390)\ngpu_ids = range(0, 1)\n", "seed": 0, "exp_name": "mask_eva_lane_det_vlm.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.00016, "memory": 8812, "data_time": 0.03555, "loss_cls": 2.24475, "loss_bbox": 2.96634, "d0.loss_cls": 2.24475, "d0.loss_bbox": 2.96634, "d1.loss_cls": 2.24475, "d1.loss_bbox": 2.96634, "d2.loss_cls": 2.24475, "d2.loss_bbox": 2.96634, "d3.loss_cls": 2.24475, "d3.loss_bbox": 2.96634, "d4.loss_cls": 2.24475, "d4.loss_bbox": 2.96634, "dn_loss_cls": 2.22987, "dn_loss_bbox": 2.67502, "d0.dn_loss_cls": 2.22987, "d0.dn_loss_bbox": 2.67502, "d1.dn_loss_cls": 2.22987, "d1.dn_loss_bbox": 2.67502, "d2.dn_loss_cls": 2.22987, "d2.dn_loss_bbox": 2.67502, "d3.dn_loss_cls": 2.22987, "d3.dn_loss_bbox": 2.67502, "d4.dn_loss_cls": 2.22987, "d4.dn_loss_bbox": 2.67502, "loss": 60.69585, "grad_norm": NaN, "time": 0.50418}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.00019, "memory": 8823, "data_time": 0.02228, "loss_cls": 2.27692, "loss_bbox": 2.80998, "d0.loss_cls": 2.27692, "d0.loss_bbox": 2.80998, "d1.loss_cls": 2.27692, "d1.loss_bbox": 2.80998, "d2.loss_cls": 2.27692, "d2.loss_bbox": 2.80998, "d3.loss_cls": 2.27692, "d3.loss_bbox": 2.80998, "d4.loss_cls": 2.27692, "d4.loss_bbox": 2.80998, "dn_loss_cls": 2.23779, "dn_loss_bbox": 2.46784, "d0.dn_loss_cls": 2.23779, "d0.dn_loss_bbox": 2.46784, "d1.dn_loss_cls": 2.23779, "d1.dn_loss_bbox": 2.46784, "d2.dn_loss_cls": 2.23779, "d2.dn_loss_bbox": 2.46784, "d3.dn_loss_cls": 2.23779, "d3.dn_loss_bbox": 2.46784, "d4.dn_loss_cls": 2.23779, "d4.dn_loss_bbox": 2.46784, "loss": 58.75514, "grad_norm": NaN, "time": 0.48139}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.00021, "memory": 8823, "data_time": 0.02528, "loss_cls": 2.25279, "loss_bbox": 2.99444, "d0.loss_cls": 2.25279, "d0.loss_bbox": 2.99444, "d1.loss_cls": 2.25279, "d1.loss_bbox": 2.99444, "d2.loss_cls": 2.25279, "d2.loss_bbox": 2.99444, "d3.loss_cls": 2.25279, "d3.loss_bbox": 2.99444, "d4.loss_cls": 2.25279, "d4.loss_bbox": 2.99444, "dn_loss_cls": 2.30118, "dn_loss_bbox": 2.72693, "d0.dn_loss_cls": 2.30118, "d0.dn_loss_bbox": 2.72693, "d1.dn_loss_cls": 2.30118, "d1.dn_loss_bbox": 2.72693, "d2.dn_loss_cls": 2.30118, "d2.dn_loss_bbox": 2.72693, "d3.dn_loss_cls": 2.30118, "d3.dn_loss_bbox": 2.72693, "d4.dn_loss_cls": 2.30118, "d4.dn_loss_bbox": 2.72693, "loss": 61.65196, "grad_norm": NaN, "time": 0.47886}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.00024, "memory": 8823, "data_time": 0.01946, "loss_cls": 2.29218, "loss_bbox": 2.86366, "d0.loss_cls": 2.29218, "d0.loss_bbox": 2.86366, "d1.loss_cls": 2.29218, "d1.loss_bbox": 2.86366, "d2.loss_cls": 2.29218, "d2.loss_bbox": 2.86366, "d3.loss_cls": 2.29218, "d3.loss_bbox": 2.86366, "d4.loss_cls": 2.29218, "d4.loss_bbox": 2.86366, "dn_loss_cls": 2.23611, "dn_loss_bbox": 2.51546, "d0.dn_loss_cls": 2.23611, "d0.dn_loss_bbox": 2.51546, "d1.dn_loss_cls": 2.23611, "d1.dn_loss_bbox": 2.51546, "d2.dn_loss_cls": 2.23611, "d2.dn_loss_bbox": 2.51546, "d3.dn_loss_cls": 2.23611, "d3.dn_loss_bbox": 2.51546, "d4.dn_loss_cls": 2.23611, "d4.dn_loss_bbox": 2.51546, "loss": 59.44442, "grad_norm": NaN, "time": 0.46946}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.00027, "memory": 8823, "data_time": 0.02011, "loss_cls": 2.30927, "loss_bbox": 2.79147, "d0.loss_cls": 2.30927, "d0.loss_bbox": 2.79147, "d1.loss_cls": 2.30927, "d1.loss_bbox": 2.79147, "d2.loss_cls": 2.30927, "d2.loss_bbox": 2.79147, "d3.loss_cls": 2.30927, "d3.loss_bbox": 2.79147, "d4.loss_cls": 2.30927, "d4.loss_bbox": 2.79147, "dn_loss_cls": 2.33425, "dn_loss_bbox": 2.49492, "d0.dn_loss_cls": 2.33425, "d0.dn_loss_bbox": 2.49492, "d1.dn_loss_cls": 2.33425, "d1.dn_loss_bbox": 2.49492, "d2.dn_loss_cls": 2.33425, "d2.dn_loss_bbox": 2.49492, "d3.dn_loss_cls": 2.33425, "d3.dn_loss_bbox": 2.49492, "d4.dn_loss_cls": 2.33425, "d4.dn_loss_bbox": 2.49492, "loss": 59.57949, "grad_norm": NaN, "time": 0.46987}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.00029, "memory": 8823, "data_time": 0.02018, "loss_cls": 2.32191, "loss_bbox": 2.84157, "d0.loss_cls": 2.32191, "d0.loss_bbox": 2.84157, "d1.loss_cls": 2.32191, "d1.loss_bbox": 2.84157, "d2.loss_cls": 2.32191, "d2.loss_bbox": 2.84157, "d3.loss_cls": 2.32191, "d3.loss_bbox": 2.84157, "d4.loss_cls": 2.32191, "d4.loss_bbox": 2.84157, "dn_loss_cls": 2.37857, "dn_loss_bbox": 2.53007, "d0.dn_loss_cls": 2.37857, "d0.dn_loss_bbox": 2.53007, "d1.dn_loss_cls": 2.37857, "d1.dn_loss_bbox": 2.53007, "d2.dn_loss_cls": 2.37857, "d2.dn_loss_bbox": 2.53007, "d3.dn_loss_cls": 2.37857, "d3.dn_loss_bbox": 2.53007, "d4.dn_loss_cls": 2.37857, "d4.dn_loss_bbox": 2.53007, "loss": 60.43276, "grad_norm": NaN, "time": 0.46284}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.00032, "memory": 8823, "data_time": 0.02367, "loss_cls": 2.31142, "loss_bbox": 2.88222, "d0.loss_cls": 2.31142, "d0.loss_bbox": 2.88222, "d1.loss_cls": 2.31142, "d1.loss_bbox": 2.88222, "d2.loss_cls": 2.31142, "d2.loss_bbox": 2.88222, "d3.loss_cls": 2.31142, "d3.loss_bbox": 2.88222, "d4.loss_cls": 2.31142, "d4.loss_bbox": 2.88222, "dn_loss_cls": 2.32672, "dn_loss_bbox": 2.56416, "d0.dn_loss_cls": 2.32672, "d0.dn_loss_bbox": 2.56416, "d1.dn_loss_cls": 2.32672, "d1.dn_loss_bbox": 2.56416, "d2.dn_loss_cls": 2.32672, "d2.dn_loss_bbox": 2.56416, "d3.dn_loss_cls": 2.32672, "d3.dn_loss_bbox": 2.56416, "d4.dn_loss_cls": 2.32672, "d4.dn_loss_bbox": 2.56416, "loss": 60.50706, "grad_norm": NaN, "time": 0.48274}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.00035, "memory": 8823, "data_time": 0.01966, "loss_cls": 2.25868, "loss_bbox": 2.95063, "d0.loss_cls": 2.25868, "d0.loss_bbox": 2.95063, "d1.loss_cls": 2.25868, "d1.loss_bbox": 2.95063, "d2.loss_cls": 2.25868, "d2.loss_bbox": 2.95063, "d3.loss_cls": 2.25868, "d3.loss_bbox": 2.95063, "d4.loss_cls": 2.25868, "d4.loss_bbox": 2.95063, "dn_loss_cls": 2.25973, "dn_loss_bbox": 2.70546, "d0.dn_loss_cls": 2.25973, "d0.dn_loss_bbox": 2.70546, "d1.dn_loss_cls": 2.25973, "d1.dn_loss_bbox": 2.70546, "d2.dn_loss_cls": 2.25973, "d2.dn_loss_bbox": 2.70546, "d3.dn_loss_cls": 2.25973, "d3.dn_loss_bbox": 2.70546, "d4.dn_loss_cls": 2.25973, "d4.dn_loss_bbox": 2.70546, "loss": 61.04699, "grad_norm": NaN, "time": 0.46648}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.00037, "memory": 8823, "data_time": 0.02128, "loss_cls": 2.27192, "loss_bbox": 3.04321, "d0.loss_cls": 2.27192, "d0.loss_bbox": 3.04321, "d1.loss_cls": 2.27192, "d1.loss_bbox": 3.04321, "d2.loss_cls": 2.27192, "d2.loss_bbox": 3.04321, "d3.loss_cls": 2.27192, "d3.loss_bbox": 3.04321, "d4.loss_cls": 2.27192, "d4.loss_bbox": 3.04321, "dn_loss_cls": 2.28939, "dn_loss_bbox": 2.79629, "d0.dn_loss_cls": 2.28939, "d0.dn_loss_bbox": 2.79629, "d1.dn_loss_cls": 2.28939, "d1.dn_loss_bbox": 2.79629, "d2.dn_loss_cls": 2.28939, "d2.dn_loss_bbox": 2.79629, "d3.dn_loss_cls": 2.28939, "d3.dn_loss_bbox": 2.79629, "d4.dn_loss_cls": 2.28939, "d4.dn_loss_bbox": 2.79629, "loss": 62.40488, "grad_norm": NaN, "time": 0.47599}
{"mode": "train", "epoch": 1, "iter": 500, "lr": 0.0004, "memory": 8823, "data_time": 0.02609, "loss_cls": 2.28638, "loss_bbox": 2.87194, "d0.loss_cls": 2.28638, "d0.loss_bbox": 2.87194, "d1.loss_cls": 2.28638, "d1.loss_bbox": 2.87194, "d2.loss_cls": 2.28638, "d2.loss_bbox": 2.87194, "d3.loss_cls": 2.28638, "d3.loss_bbox": 2.87194, "d4.loss_cls": 2.28638, "d4.loss_bbox": 2.87194, "dn_loss_cls": 2.2944, "dn_loss_bbox": 2.60774, "d0.dn_loss_cls": 2.2944, "d0.dn_loss_bbox": 2.60774, "d1.dn_loss_cls": 2.2944, "d1.dn_loss_bbox": 2.60774, "d2.dn_loss_cls": 2.2944, "d2.dn_loss_bbox": 2.60774, "d3.dn_loss_cls": 2.2944, "d3.dn_loss_bbox": 2.60774, "d4.dn_loss_cls": 2.2944, "d4.dn_loss_bbox": 2.60774, "loss": 60.36282, "grad_norm": NaN, "time": 0.48634}
